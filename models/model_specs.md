## Claude 3.7 sonnet
* context window - 200k tokens
* output limit - 128k tokens
* pricing - $3/M input & $10/M output
* Feature - Hybrid reasoning

## Claude 4.5 sonnet
* context window - 200k tokens, upto 1M (beta)
* output limit - 128k tokens
* pricing - $3/M input & $10/M output
* Feature - Hybrid reasoning, strong coding, context awareness
* Best for - Deep analysis and agentic workflow

## GPT 5.1
* context window - 400k tokens
* output limit - 128k tokens
* pricing - $1.25/M input & $10/M output
* Best for - Deep reasoning, long docs and agentic workflow

## GPT 4.1
* context window - 1000k tokens
* Best for - Large docs, large code base, long conversation, agent

## all-miniLM-L6-V2
* Model Type - Sentence embedding
* Embedding size - 384 dimensions
* Architecture - L6 (6 transformer layers)
* Max input length - 256 tokens
* Not suitable for large documents (large chunks)

## BAAI/bge-base-en-v1.5
* Embedding size - 768 dimensions
* Max input length - 512 tokens
* Size - 438 MB
* Excellent for RAG retrieval

## amazon.titan-embed-text-v2:0
* Embedding size - 1024 (we can downgrade)
* Max input length - 8192
* Excellent for RAG, document search

## text-embedding-3-large
* Embedding size - 3072 (we can downgrade)
* Max input length - 8192
* Excellent for RAG, document search